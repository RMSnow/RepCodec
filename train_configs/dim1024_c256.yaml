###########################################################
#                   DATA SETTING                          #
###########################################################
data:
    path: "/fsx-project/xueyao/data/hubert_large_l18"
    subset:
        train: "train"
        valid: "dev"
        test:  "dev"

###########################################################
#                   MODEL SETTING                         #
###########################################################
model_params:
    input_channels: 1024
    output_channels: 1024
    encode_channels: 1024
    decode_channels: 1024
    code_dim: 1024
    codebook_num: 1
    codebook_size: 256
    bias: true
    enc_ratios: [1, 1]
    dec_ratios: [1, 1]
    enc_strides: [1, 1]  # no downsampling
    dec_strides: [1, 1]
    enc_kernel_size: 3
    dec_kernel_size: 3
    enc_block_dilations: [1, 1]
    enc_block_kernel_size: 3
    dec_block_dilations: [1, 1]
    dec_block_kernel_size: 3

###########################################################
#                 METRIC LOSS SETTING                     #
###########################################################
repr_reconstruct_loss_params:
    loss_type: l2

###########################################################
#                  LOSS WEIGHT SETTING                    #
###########################################################
lambda_vq_loss: 1.0      # Loss weight of vector quantize loss.
lambda_repr_reconstruct_loss: 45.0

###########################################################
#                  DATA LOADER SETTING                    #
###########################################################
batch_size: 32              # Batch size.
batch_length: 96            # Length of each audio in batch (training w/o adv).
pin_memory: true            # Whether to pin memory in Pytorch DataLoader.
num_workers: 4              # Number of workers in Pytorch DataLoader.

###########################################################
#             OPTIMIZER & SCHEDULER SETTING               #
###########################################################
model_optimizer_type: Adam
model_optimizer_params:
    lr: 1.0e-4
    betas: [0.5, 0.9]
    weight_decay: 0.0
model_scheduler_type: StepLR
model_scheduler_params:
    step_size: 200000      # Model's scheduler step size.
    gamma: 1.0
grad_norm: -1

###########################################################
#                    INTERVAL SETTING                     #
###########################################################
train_max_steps: 200000            # Number of training steps. (w/o adv)
save_interval_steps: 20000         # Interval steps to save checkpoint.
eval_interval_steps: 2000          # Interval steps to evaluate the network.
log_interval_steps: 100            # Interval steps to record the training log.
